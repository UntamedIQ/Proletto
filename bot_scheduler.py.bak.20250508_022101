import os
import time
import logging
import schedule
import threading
import traceback
import json
import sys
from datetime import datetime, timedelta

# Configure logging with rotation
log_file = "bot.log"
max_log_size = 10 * 1024 * 1024  # 10 MB

# Check if log needs rotation
try:
    if os.path.exists(log_file) and os.path.getsize(log_file) > max_log_size:
        # Backup old log
        if os.path.exists(f"{log_file}.bak"):
            os.remove(f"{log_file}.bak")
        os.rename(log_file, f"{log_file}.bak")
except Exception:
    # Don't let log rotation issues prevent the scheduler from running
    pass

# Configure logging with both file and console output
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(log_file),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger('bot_scheduler')

# Create a state file to track runs and failures
STATE_FILE = "bot_scheduler_state.json"

def load_state():
    """Load the scheduler state from file"""
    if os.path.exists(STATE_FILE):
        try:
            with open(STATE_FILE, 'r') as f:
                return json.load(f)
        except Exception as e:
            logger.error(f"Failed to load state file: {e}")
    
    # Return default state if file doesn't exist or has errors
    return {
        "last_successful_run": None,
        "consecutive_failures": 0,
        "total_runs": 0,
        "total_successes": 0,
        "total_failures": 0,
        "last_run": None,
        "created_at": datetime.utcnow().isoformat()
    }

def save_state(state):
    """Save the scheduler state to file"""
    try:
        with open(STATE_FILE, 'w') as f:
            json.dump(state, f, indent=2)
    except Exception as e:
        logger.error(f"Failed to save state file: {e}")

def run_bot():
    """
    Function to run the bot code with built-in recovery mechanisms.
    This function will be scheduled to run on a defined schedule.
    """
    # Load the current state
    state = load_state()
    
    # Update run stats
    state["total_runs"] += 1
    state["last_run"] = datetime.utcnow().isoformat()
    
    try:
        logger.info("Starting bot execution at %s", datetime.now())
        
        # Import the bot code module
        import bot_code
        
        # Call the bot's main function
        success = bot_code.run()
        
        if success:
            logger.info("Bot execution completed successfully at %s", datetime.now())
            state["last_successful_run"] = datetime.utcnow().isoformat()
            state["consecutive_failures"] = 0
            state["total_successes"] += 1
        else:
            logger.warning("Bot execution completed but reported failure at %s", datetime.now())
            state["consecutive_failures"] += 1
            state["total_failures"] += 1
            
    except Exception as e:
        # Capture detailed error information
        exc_type, exc_value, exc_traceback = sys.exc_info()
        error_details = traceback.format_exception(exc_type, exc_value, exc_traceback)
        error_text = ''.join(error_details)
        
        # Log the detailed error
        logger.error("Error running bot: %s\nTraceback:\n%s", str(e), error_text)
        
        # Update state
        state["consecutive_failures"] += 1
        state["total_failures"] += 1
    
    # Implement recovery logic based on failure pattern
    if state["consecutive_failures"] >= 3:
        logger.warning("Detected %s consecutive failures, adjusting schedule...", 
                      state["consecutive_failures"])
        
        # For persistent failures, we don't want to stop trying, but we can add
        # some additional error handling or notification here in the future
    
    # Save the updated state
    save_state(state)
    
    # Return success/failure for potential upstream handling
    return state["consecutive_failures"] == 0

def run_threaded(job_func):
    """Run the scheduled job in a separate thread."""
    job_thread = threading.Thread(target=job_func)
    job_thread.daemon = True  # Allow clean shutdown
    job_thread.start()
    return job_thread

def setup_schedule():
    """
    Set up the schedule for running the bot.
    
    We now run the bot on multiple schedules:
    1. Monday and Thursday at 8:00 AM (primary schedule)
    2. Every day at 4:00 AM for daily updates
    3. Weekly comprehensive scrape on Sunday at 1:00 AM
    """
    # Primary schedule - Monday and Thursday at 8:00 AM
    schedule.every().monday.at("08:00").do(run_threaded, run_bot)
    schedule.every().thursday.at("08:00").do(run_threaded, run_bot)
    
    # Daily quick update at 4:00 AM
    schedule.every().day.at("04:00").do(run_threaded, run_bot)
    
    # Weekly comprehensive scrape (longer run)
    schedule.every().sunday.at("01:00").do(run_threaded, run_bot)
    
    # Add a retry mechanism for failures
    def check_for_retry():
        state = load_state()
        last_run_time = None
        
        if state["last_run"]:
            try:
                last_run_time = datetime.fromisoformat(state["last_run"])
            except (ValueError, TypeError) as e:
                logger.error(f"Error parsing last run time: {e}")
                return
        
        # If there was a recent failure and it's been more than 3 hours
        if (state["consecutive_failures"] > 0 and last_run_time and 
            datetime.utcnow() - last_run_time > timedelta(hours=3)):
            logger.info("Scheduling retry after recent failure")
            run_threaded(run_bot)
    
    # Check for potential retries every 3 hours
    schedule.every(3).hours.do(check_for_retry)
    
    logger.info("Bot scheduled with comprehensive schedule for reliability")
    logger.info("- Primary runs: Monday and Thursday at 8:00 AM")
    logger.info("- Daily updates: Every day at 4:00 AM")
    logger.info("- Weekly comprehensive scrape: Sunday at 1:00 AM")
    logger.info("- Auto-retry mechanism: Active")

def run_scheduler():
    """
    Main function to run the scheduler continuously.
    Includes watchdog and recovery mechanisms.
    """
    setup_schedule()
    
    # Run the scheduler loop with built-in recovery
    consecutive_scheduler_errors = 0
    last_alive_signal = datetime.utcnow()
    
    while True:
        try:
            # Log alive signal every 12 hours for monitoring
            if datetime.utcnow() - last_alive_signal > timedelta(hours=12):
                logger.info("Scheduler alive signal")
                last_alive_signal = datetime.utcnow()
            
            # Run any pending scheduled jobs
            schedule.run_pending()
            
            # Reset error counter on successful cycle
            consecutive_scheduler_errors = 0
            
            # Sleep until next check
            time.sleep(60)  # Check the schedule every minute
            
        except Exception as e:
            # Capture scheduler errors
            exc_type, exc_value, exc_traceback = sys.exc_info()
            error_details = traceback.format_exception(exc_type, exc_value, exc_traceback)
            error_text = ''.join(error_details)
            
            consecutive_scheduler_errors += 1
            logger.error("Scheduler error (%s consecutive): %s\nTraceback:\n%s", 
                         consecutive_scheduler_errors, str(e), error_text)
            
            # If we're having persistent scheduler problems, implement recovery
            if consecutive_scheduler_errors >= 5:
                logger.warning("Multiple scheduler errors detected, attempting recovery")
                try:
                    # Clear all existing jobs and reset
                    schedule.clear()
                    setup_schedule()
                    logger.info("Scheduler reset complete")
                except Exception as reset_err:
                    logger.error("Failed to reset scheduler: %s", str(reset_err))
            
            # Sleep before trying again (with exponential backoff)
            backoff_seconds = min(60 * (2 ** (consecutive_scheduler_errors - 1)), 3600)
            logger.info("Scheduler backing off for %s seconds", backoff_seconds)
            time.sleep(backoff_seconds)

def run_manual():
    """Run the bot manually once, for testing or initial data population"""
    logger.info("Running bot manually (one-time execution)")
    return run_bot()

if __name__ == "__main__":
    # Process command line arguments
    if len(sys.argv) > 1 and sys.argv[1] == "--run-once":
        # Run the bot once immediately and exit
        run_manual()
    else:
        # Start the scheduler
        logger.info("Starting bot scheduler")
        state = load_state()
        logger.info(f"Current state: {json.dumps(state, indent=2)}")
        
        # Run the bot immediately on startup, then continue with the schedule
        logger.info("Running initial job on startup")
        run_threaded(run_bot)
        
        # Start the main scheduler
        run_scheduler()